# Data cleaning case study

In this activity, you will work with your co-participants on a case study that involves data cleaning by handling missing data and removing outliers.

## Steps to solve the case study: 

 * Create a google colab notebook for this activity;
 * Read the description of the dataset in Kaggle;
 * Download the dataset from Kaggle and then load it into the google colab notebook. You may use other methods to make the dataset available for reading in the notebook such as storing the dataset in google drive and mounting the drive into the colab notebook;
 * Use the pandas' package in python to read the dataset as a DataFrame;
 * Clean the dataset by checking and handling any missing data. In this step try to use the best practice for handling missing data based on the type of the features;
 * Then use an appropriate method to detect and remove outliers;
 * Add explanatory comments to the google colab notebook in the text cells ;
 * Save the google colab notebook in your GitHub repository. Create a separate Github repository for this tutorial that will be used to save all case study notebooks.

A dataset modified for this session can be cloned from the GitHub repository in the file EDA_insurance_modified.csv

<a href='https://github.com/mkjubran/AIData.git'>Source of the dataset for the data cleaning case study</a>

<a href='https://www.kaggle.com/datasets/teertha/ushealthinsurancedataset?resource=download'>The description of the fields of the dataset can be found on Kaggle using this link</a>