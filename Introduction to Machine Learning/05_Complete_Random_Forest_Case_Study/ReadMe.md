# Complete Random Forest case study

In this activity, you will work with your co-participants to solve a classification problem of labeled data using the random forest algorithm. In the beginning, you need to use the learned skills and techniques to clean the labeled data and select the right features for the model. You will also need to encode categorical and ordinal features. Then, you will fit the random forest model to the cleaned dataset and evaluate and comment on the performance of the fitted model.

## Steps to solve the case study: 
 * Create a google colab notebook for this activity;
 * Read the description of the dataset in Kaggle;
 * Download the dataset from Kaggle and then load it into the google colab notebook. You may use other methods to make the dataset available for reading in the notebook such as storing the dataset in google drive and mounting the drive into the colab notebook;
 * Use EDA techniques to clean the dataset, encode any categorical data, and use feature selection and engineering to select the best features to solve the case study;
 * Split the dataset into training and testing datasets;
 * Use the sklearn to fit and evaluate the random forest classification model;
 * Comment on the evaluation of the random forest classifier;
 * Add explanatory comments to the google colab notebook in the text cells;
 * Save the google colab notebook in the GitHub repository.

The dataset for this session can be cloned from the GitHub repository in the file BreastCancerPrediction.csv

<a href='https://github.com/mkjubran/AIData.git'>Source of the dataset for the Random Forest case study</a>

<a href='https://www.kaggle.com/code/gpreda/breast-cancer-prediction-from-cytopathology-data/data'>The description of the fields of the dataset can be found on Kaggle using this link</a>